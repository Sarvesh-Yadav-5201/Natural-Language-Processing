{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Nn1FF3_AmIgj"},"source":["# <b> PROJECT :Character-level Language Translation using LSTM-based Seq2Seq Model\n","\n","OBJECTIVE : \n","           \n","We will implement a character-level sequence-to-sequence model, processing the input character-by-character and generating the output character-by-character (English ----> FRENCH).\n","             \n","> Example : \"the cat sat on the mat\" -> [Seq2Seq model] -> \"le chat etait assis sur le tapis\"\n","\n","___________________\n","</b>\n","Here's a summary of our process:\n","\n","1) Turn the sentences into 3 Numpy arrays, encoder_input_data, decoder_input_data, decoder_target_data:\n","\n","    * encoder_input_data is a 3D array of shape (num_pairs, max_english_sentence_length, num_english_characters) containing a one-hot vectorization of the English sentences.\n","    * decoder_input_data is a 3D array of shape (num_pairs, max_french_sentence_length, num_french_characters) containg a one-hot vectorization of the French sentences.\n","    * decoder_target_data is the same as decoder_input_data but offset by one timestep. decoder_target_data[:, t, :] will be the same as decoder_input_data[:, t + 1, :].\n","\n","    \n","\n","2) Train a basic LSTM-based Seq2Seq model to predict decoder_target_data given encoder_input_data and decoder_input_data. Our model uses teacher forcing.\n","\n","3) Decode some sentences to check that the model is working (i.e. turn samples from encoder_input_data into corresponding samples from decoder_target_data).\n","\n","________________________________________________________________"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4428,"status":"ok","timestamp":1678794396227,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"gvO1GIeUmO8f","outputId":"6147f494-a5d7-4616-eaa1-06653117ddc5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2125,"status":"ok","timestamp":1678794398349,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"-pciVLaUmIgu"},"outputs":[],"source":["# Importing Libraries\n","\n","import pandas as pd\n","import numpy as np\n","\n","import tensorflow as tf \n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input , LSTM , Dense"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1678794398350,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"Ylt8xj3MmIgy"},"outputs":[],"source":["## Defining some Model Training Parameters:\n","\n","batch_size= 64              # Batch size for the training \n","epochs = 100                # Number of epochs to train for\n","\n","latent_dim = 256            # latent dimensionality for ENCODING SPACE\n","num_samples = 10000         # Number of Samples to train on\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1678794398350,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"F4rrjM5LmIg0","outputId":"b90b21a9-5163-44bf-b308-e2c83b7f23d0"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-08b76cf5-e882-4e54-9693-419a057ef7de\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>Va !</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Go.</td>\n","      <td>Marche.</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Go.</td>\n","      <td>En route !</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Go.</td>\n","      <td>Bouge !</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Hi.</td>\n","      <td>Salut !</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>208901</th>\n","      <td>A carbon footprint is the amount of carbon dio...</td>\n","      <td>Une empreinte carbone est la somme de pollutio...</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n","    </tr>\n","    <tr>\n","      <th>208902</th>\n","      <td>Death is something that we're often discourage...</td>\n","      <td>La mort est une chose qu'on nous décourage sou...</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n","    </tr>\n","    <tr>\n","      <th>208903</th>\n","      <td>Since there are usually multiple websites on a...</td>\n","      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n","    </tr>\n","    <tr>\n","      <th>208904</th>\n","      <td>If someone who doesn't know your background sa...</td>\n","      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n","    </tr>\n","    <tr>\n","      <th>208905</th>\n","      <td>It may be impossible to get a completely error...</td>\n","      <td>Il est peut-être impossible d'obtenir un Corpu...</td>\n","      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>208906 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08b76cf5-e882-4e54-9693-419a057ef7de')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-08b76cf5-e882-4e54-9693-419a057ef7de button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-08b76cf5-e882-4e54-9693-419a057ef7de');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                        0  \\\n","0                                                     Go.   \n","1                                                     Go.   \n","2                                                     Go.   \n","3                                                     Go.   \n","4                                                     Hi.   \n","...                                                   ...   \n","208901  A carbon footprint is the amount of carbon dio...   \n","208902  Death is something that we're often discourage...   \n","208903  Since there are usually multiple websites on a...   \n","208904  If someone who doesn't know your background sa...   \n","208905  It may be impossible to get a completely error...   \n","\n","                                                        1  \\\n","0                                                    Va !   \n","1                                                 Marche.   \n","2                                              En route !   \n","3                                                 Bouge !   \n","4                                                 Salut !   \n","...                                                   ...   \n","208901  Une empreinte carbone est la somme de pollutio...   \n","208902  La mort est une chose qu'on nous décourage sou...   \n","208903  Puisqu'il y a de multiples sites web sur chaqu...   \n","208904  Si quelqu'un qui ne connaît pas vos antécédent...   \n","208905  Il est peut-être impossible d'obtenir un Corpu...   \n","\n","                                                        2  \n","0       CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n","1       CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n","2       CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n","3       CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n","4       CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n","...                                                   ...  \n","208901  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n","208902  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n","208903  CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n","208904  CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n","208905  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n","\n","[208906 rows x 3 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Gettging the data:\n","data = pd.read_csv('/content/drive/MyDrive/UNIV.AI/NLP Intro /Datasets/fra.txt', sep = '\\t', header= None)\n","data"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":1340,"status":"ok","timestamp":1678794399676,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"A4EsPg7ymIg3","outputId":"3b42aaf4-316a-40dd-de72-0b09ac8ada4e"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-0b490cb1-84fc-451b-9452-e6367809b37d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>English</th>\n","      <th>French</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Go.</td>\n","      <td>Va !</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Go.</td>\n","      <td>Marche.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Go.</td>\n","      <td>En route !</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Go.</td>\n","      <td>Bouge !</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Hi.</td>\n","      <td>Salut !</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b490cb1-84fc-451b-9452-e6367809b37d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0b490cb1-84fc-451b-9452-e6367809b37d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0b490cb1-84fc-451b-9452-e6367809b37d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["  English      French\n","0     Go.        Va !\n","1     Go.     Marche.\n","2     Go.  En route !\n","3     Go.     Bouge !\n","4     Hi.     Salut !"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["data = data.rename(columns= {0:'English', 1: 'French'}).drop(2, axis= 1)\n","data.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1678794399677,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"bxtRl1qsmIg5"},"outputs":[],"source":["## We now need to make data ready for modeling \n","\n","# Getting all input text, output text. \n","input_text = data['English'][:num_samples]              # English Sentences are the Input text\n","target_text = '\\t'+ data['French'][:num_samples]+ '\\n'    # we use tab '\\t' and '\\n' for the as the start and end sequence for the target text"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1678794399678,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"Bg6aM-mcmIg6","outputId":"b61cbbb8-f878-40dd-ce9d-c3ddbb0e6adf"},"outputs":[{"data":{"text/plain":["0     Go.\n","1     Go.\n","2     Go.\n","3     Go.\n","4     Hi.\n","5     Hi.\n","6    Run!\n","7    Run!\n","8    Run!\n","9    Run!\n","Name: English, dtype: object"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["input_text[:10]"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1678794399678,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"Via3kBDVmIg8","outputId":"154ee247-eb5c-4eef-e205-9c5627474e1c"},"outputs":[{"data":{"text/plain":["0                              \\tVa !\\n\n","1                           \\tMarche.\\n\n","2                        \\tEn route !\\n\n","3                           \\tBouge !\\n\n","4                           \\tSalut !\\n\n","5                            \\tSalut.\\n\n","6                           \\tCours !\\n\n","7                          \\tCourez !\\n\n","8    \\tPrenez vos jambes à vos cous !\\n\n","9                            \\tFile !\\n\n","Name: French, dtype: object"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["target_text[:10]"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1678794399679,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"wxNOvpvymIg-"},"outputs":[],"source":["# Now we get the unique input characters used in input and target text:\n","input_char = set()\n","target_char = set()\n","\n","for i in range(num_samples):\n","    for char in (input_text[i]):\n","        input_char.add(str(char))\n","\n","    for char in (target_text[i]):\n","        target_char.add(str(char))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1678794399679,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"6_IWHm9OmIg_","outputId":"878f18f9-2ac3-49a3-d333-6c52f4a99196"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Length of Input Characters (ENGLISH)  : 71\n","Length of target Characters (FRENCH)  : 93\n","\n"]}],"source":["print(f'''\n","Length of Input Characters (ENGLISH)  : {len(input_char)}\n","Length of target Characters (FRENCH)  : {len(target_char)}\n","''')"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1678794399680,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"Ixhl1jt5mIhB","outputId":"3ea1d65e-e22f-4a96-c0c9-ba36bd507de6"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","PARAMETERS : \n","* Number of Samples                 : 10000\n","* Number of unique input tokens     : 71 \n","* Number of unique target tokens    : 93 \n","* Max Sequence lenght of Input      : 15\n","* Max Sequence lenght of target     : 59\n","\n","\n","\n"]}],"source":["# declaring few parameters that we may need in the future:\n","\n","input_char = sorted(list(input_char))\n","target_char= sorted(list(target_char))\n","\n","num_encoder_tokens = len(input_char)\n","num_decoder_tokens = len(target_char)\n","\n","max_encoder_seq_len = max([len(texts) for texts in input_text])\n","max_decoder_seq_len = max([len(texts) for texts in target_text])\n","\n","\n","print (f'''\n","PARAMETERS : \n","* Number of Samples                 : {len(input_text)}\n","* Number of unique input tokens     : {num_encoder_tokens} \n","* Number of unique target tokens    : {num_decoder_tokens} \n","* Max Sequence lenght of Input      : {max_encoder_seq_len}\n","* Max Sequence lenght of target     : {max_decoder_seq_len}\n","\n","\n","''')"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1678794399680,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"urWq0DwRmIhD"},"outputs":[],"source":["# Assigning Tokens to each and every characters we have in input and output texts:\n","\n","input_token_index = dict([(char, i) for i , char in enumerate (input_char)])\n","\n","target_token_index = dict([(char, i) for i , char in enumerate (target_char)])"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1678794399681,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"pwcjT5XVmIhE","outputId":"0a4503c3-4eab-488e-bf76-3f491d9656ac"},"outputs":[{"data":{"text/plain":["(10000, 15, 71)"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(10000, 59, 93)"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(10000, 59, 93)"]},"metadata":{},"output_type":"display_data"}],"source":["## One- hot Representation using numpy:\n","\n","# Creating the required variables with required shapes:\n","\n","encoder_input_data = np.zeros((len(input_text), max_encoder_seq_len, num_encoder_tokens), dtype= 'float32')\n","decoder_input_data = np.zeros((len(input_text), max_decoder_seq_len, num_decoder_tokens), dtype= 'float32')\n","decoder_target_data = np.zeros((len(input_text), max_decoder_seq_len, num_decoder_tokens), dtype= 'float32')\n","\n","display(encoder_input_data.shape, decoder_input_data.shape, decoder_target_data.shape)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1678794399681,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"hve_zDjpmIhF"},"outputs":[],"source":["# one hot representation: \n","\n","for i, (input_text_, target_text_) in enumerate(zip(input_text, target_text)):\n","    for t, char in enumerate(input_text_):\n","        encoder_input_data[i, t, input_token_index[char]] = 1.\n","    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n","    for t, char in enumerate(target_text_):\n","        # decoder_target_data is ahead of decoder _input_data by one timestep\n","        decoder_input_data[i, t, target_token_index[char]] = 1.\n","        if t > 0:\n","            # decoder_target_data will be ahead by one timestep\n","            # and will not include the start character.\n","            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n","    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n","    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1678794399681,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"uNKja87OmIhH","outputId":"2abb4b30-2a51-42f1-b6fc-f970d7e6e0a1"},"outputs":[{"data":{"text/plain":["array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0.], dtype=float32)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["encoder_input_data[0][0]"]},{"cell_type":"markdown","metadata":{"id":"OdwmdpHQmIhI"},"source":["MODELING : LSTM (seq2se1)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":2164,"status":"ok","timestamp":1678794401830,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"GVt0V-mQmIhI"},"outputs":[],"source":["# Defining the input Layer and process it .\n","\n","encoder_inputs  = Input(shape= (None, num_encoder_tokens))\n","\n","encoder = LSTM (latent_dim, return_state= True)\n","\n","encoder_outputs , state_h, state_c = encoder(encoder_inputs)\n","\n","# We done need the encoder_outputs while working with endcoders :\n","\n","encoder_states = [state_h, state_c]"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":972,"status":"ok","timestamp":1678794402799,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"dfw-D6mjmIhJ"},"outputs":[],"source":["# setting up the decoder, using the encoder states as initial state:\n","\n","decoder_inputs = Input(shape = (None , num_decoder_tokens))\n","\n","decoder_lstm  = LSTM (latent_dim, return_sequences= True , return_state= True)\n","\n","# We don't care about the decoder state here . We want the outpts here:\n","\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state =encoder_states)\n","\n","decoder_dense = Dense(num_decoder_tokens, activation= 'softmax')\n","decoder_outputs = decoder_dense (decoder_outputs)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":330114,"status":"ok","timestamp":1678794732911,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"oocbM15qmIhK","outputId":"a6e32f8e-18e6-4fb5-b954-5170d8f7ec0d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/170\n","118/118 [==============================] - 11s 22ms/step - loss: 1.2072 - accuracy: 0.7339 - val_loss: 1.1573 - val_accuracy: 0.7133\n","Epoch 2/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.9380 - accuracy: 0.7483 - val_loss: 0.9981 - val_accuracy: 0.7264\n","Epoch 3/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.8539 - accuracy: 0.7636 - val_loss: 0.9135 - val_accuracy: 0.7424\n","Epoch 4/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.7708 - accuracy: 0.7846 - val_loss: 0.8823 - val_accuracy: 0.7611\n","Epoch 5/170\n","118/118 [==============================] - 2s 18ms/step - loss: 0.6959 - accuracy: 0.8030 - val_loss: 0.7606 - val_accuracy: 0.7775\n","Epoch 6/170\n","118/118 [==============================] - 2s 16ms/step - loss: 0.6406 - accuracy: 0.8144 - val_loss: 0.7386 - val_accuracy: 0.7812\n","Epoch 7/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.6091 - accuracy: 0.8222 - val_loss: 0.6963 - val_accuracy: 0.7971\n","Epoch 8/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.5864 - accuracy: 0.8284 - val_loss: 0.6725 - val_accuracy: 0.8005\n","Epoch 9/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.5662 - accuracy: 0.8338 - val_loss: 0.6554 - val_accuracy: 0.8060\n","Epoch 10/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.5476 - accuracy: 0.8389 - val_loss: 0.6642 - val_accuracy: 0.8021\n","Epoch 11/170\n","118/118 [==============================] - 1s 13ms/step - loss: 0.5320 - accuracy: 0.8436 - val_loss: 0.6414 - val_accuracy: 0.8128\n","Epoch 12/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.5177 - accuracy: 0.8474 - val_loss: 0.6096 - val_accuracy: 0.8180\n","Epoch 13/170\n","118/118 [==============================] - 2s 15ms/step - loss: 0.5045 - accuracy: 0.8515 - val_loss: 0.5994 - val_accuracy: 0.8195\n","Epoch 14/170\n","118/118 [==============================] - 2s 18ms/step - loss: 0.4918 - accuracy: 0.8550 - val_loss: 0.5831 - val_accuracy: 0.8263\n","Epoch 15/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.4808 - accuracy: 0.8580 - val_loss: 0.5775 - val_accuracy: 0.8295\n","Epoch 16/170\n","118/118 [==============================] - 1s 13ms/step - loss: 0.4697 - accuracy: 0.8615 - val_loss: 0.5583 - val_accuracy: 0.8360\n","Epoch 17/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.4594 - accuracy: 0.8644 - val_loss: 0.5486 - val_accuracy: 0.8377\n","Epoch 18/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.4501 - accuracy: 0.8671 - val_loss: 0.5558 - val_accuracy: 0.8345\n","Epoch 19/170\n","118/118 [==============================] - 1s 13ms/step - loss: 0.4420 - accuracy: 0.8695 - val_loss: 0.5364 - val_accuracy: 0.8417\n","Epoch 20/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.4331 - accuracy: 0.8718 - val_loss: 0.5322 - val_accuracy: 0.8437\n","Epoch 21/170\n","118/118 [==============================] - 2s 15ms/step - loss: 0.4253 - accuracy: 0.8741 - val_loss: 0.5314 - val_accuracy: 0.8428\n","Epoch 22/170\n","118/118 [==============================] - 2s 16ms/step - loss: 0.4187 - accuracy: 0.8758 - val_loss: 0.5371 - val_accuracy: 0.8405\n","Epoch 23/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.4115 - accuracy: 0.8779 - val_loss: 0.5135 - val_accuracy: 0.8499\n","Epoch 24/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.4046 - accuracy: 0.8799 - val_loss: 0.5229 - val_accuracy: 0.8451\n","Epoch 25/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.3982 - accuracy: 0.8816 - val_loss: 0.5078 - val_accuracy: 0.8493\n","Epoch 26/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.3922 - accuracy: 0.8838 - val_loss: 0.5081 - val_accuracy: 0.8503\n","Epoch 27/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.3866 - accuracy: 0.8852 - val_loss: 0.5040 - val_accuracy: 0.8506\n","Epoch 28/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.3808 - accuracy: 0.8867 - val_loss: 0.5010 - val_accuracy: 0.8530\n","Epoch 29/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.3753 - accuracy: 0.8882 - val_loss: 0.4961 - val_accuracy: 0.8541\n","Epoch 30/170\n","118/118 [==============================] - 2s 18ms/step - loss: 0.3704 - accuracy: 0.8893 - val_loss: 0.4885 - val_accuracy: 0.8570\n","Epoch 31/170\n","118/118 [==============================] - 2s 15ms/step - loss: 0.3646 - accuracy: 0.8914 - val_loss: 0.5000 - val_accuracy: 0.8526\n","Epoch 32/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.3593 - accuracy: 0.8926 - val_loss: 0.4966 - val_accuracy: 0.8547\n","Epoch 33/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.3545 - accuracy: 0.8940 - val_loss: 0.4823 - val_accuracy: 0.8578\n","Epoch 34/170\n","118/118 [==============================] - 1s 13ms/step - loss: 0.3497 - accuracy: 0.8955 - val_loss: 0.4815 - val_accuracy: 0.8587\n","Epoch 35/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.3448 - accuracy: 0.8970 - val_loss: 0.4853 - val_accuracy: 0.8577\n","Epoch 36/170\n","118/118 [==============================] - 1s 12ms/step - loss: 0.3400 - accuracy: 0.8983 - val_loss: 0.4790 - val_accuracy: 0.8595\n","Epoch 37/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.3355 - accuracy: 0.8995 - val_loss: 0.4806 - val_accuracy: 0.8610\n","Epoch 38/170\n","118/118 [==============================] - 2s 18ms/step - loss: 0.3316 - accuracy: 0.9006 - val_loss: 0.4681 - val_accuracy: 0.8642\n","Epoch 39/170\n","118/118 [==============================] - 2s 16ms/step - loss: 0.3265 - accuracy: 0.9020 - val_loss: 0.4904 - val_accuracy: 0.8576\n","Epoch 40/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.3227 - accuracy: 0.9034 - val_loss: 0.4763 - val_accuracy: 0.8615\n","Epoch 41/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.3180 - accuracy: 0.9047 - val_loss: 0.4720 - val_accuracy: 0.8634\n","Epoch 42/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.3142 - accuracy: 0.9057 - val_loss: 0.4870 - val_accuracy: 0.8593\n","Epoch 43/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.3101 - accuracy: 0.9071 - val_loss: 0.4718 - val_accuracy: 0.8621\n","Epoch 44/170\n","118/118 [==============================] - 2s 16ms/step - loss: 0.3059 - accuracy: 0.9082 - val_loss: 0.4672 - val_accuracy: 0.8644\n","Epoch 45/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.3015 - accuracy: 0.9093 - val_loss: 0.4765 - val_accuracy: 0.8627\n","Epoch 46/170\n","118/118 [==============================] - 2s 19ms/step - loss: 0.2980 - accuracy: 0.9104 - val_loss: 0.4590 - val_accuracy: 0.8678\n","Epoch 47/170\n","118/118 [==============================] - 2s 15ms/step - loss: 0.2935 - accuracy: 0.9117 - val_loss: 0.4644 - val_accuracy: 0.8661\n","Epoch 48/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.2904 - accuracy: 0.9128 - val_loss: 0.4703 - val_accuracy: 0.8654\n","Epoch 49/170\n","118/118 [==============================] - 1s 13ms/step - loss: 0.2863 - accuracy: 0.9138 - val_loss: 0.4685 - val_accuracy: 0.8664\n","Epoch 50/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.2823 - accuracy: 0.9152 - val_loss: 0.4614 - val_accuracy: 0.8681\n","Epoch 51/170\n","118/118 [==============================] - 1s 13ms/step - loss: 0.2790 - accuracy: 0.9159 - val_loss: 0.4664 - val_accuracy: 0.8674\n","Epoch 52/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.2754 - accuracy: 0.9169 - val_loss: 0.4644 - val_accuracy: 0.8681\n","Epoch 53/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.2715 - accuracy: 0.9185 - val_loss: 0.4639 - val_accuracy: 0.8683\n","Epoch 54/170\n","118/118 [==============================] - 2s 15ms/step - loss: 0.2683 - accuracy: 0.9190 - val_loss: 0.4670 - val_accuracy: 0.8676\n","Epoch 55/170\n","118/118 [==============================] - 2s 19ms/step - loss: 0.2644 - accuracy: 0.9205 - val_loss: 0.4606 - val_accuracy: 0.8696\n","Epoch 56/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.2611 - accuracy: 0.9214 - val_loss: 0.4654 - val_accuracy: 0.8690\n","Epoch 57/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.2581 - accuracy: 0.9219 - val_loss: 0.4755 - val_accuracy: 0.8660\n","Epoch 58/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.2548 - accuracy: 0.9232 - val_loss: 0.4713 - val_accuracy: 0.8671\n","Epoch 59/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.2512 - accuracy: 0.9242 - val_loss: 0.4613 - val_accuracy: 0.8705\n","Epoch 60/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.2480 - accuracy: 0.9251 - val_loss: 0.4641 - val_accuracy: 0.8696\n","Epoch 61/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.2452 - accuracy: 0.9258 - val_loss: 0.4642 - val_accuracy: 0.8712\n","Epoch 62/170\n","118/118 [==============================] - 2s 15ms/step - loss: 0.2413 - accuracy: 0.9273 - val_loss: 0.4714 - val_accuracy: 0.8697\n","Epoch 63/170\n","118/118 [==============================] - 2s 16ms/step - loss: 0.2387 - accuracy: 0.9278 - val_loss: 0.4776 - val_accuracy: 0.8694\n","Epoch 64/170\n","118/118 [==============================] - 2s 15ms/step - loss: 0.2356 - accuracy: 0.9291 - val_loss: 0.4774 - val_accuracy: 0.8697\n","Epoch 65/170\n","118/118 [==============================] - 1s 13ms/step - loss: 0.2326 - accuracy: 0.9296 - val_loss: 0.4759 - val_accuracy: 0.8692\n","Epoch 66/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.2301 - accuracy: 0.9304 - val_loss: 0.4718 - val_accuracy: 0.8715\n","Epoch 67/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.2268 - accuracy: 0.9314 - val_loss: 0.4781 - val_accuracy: 0.8692\n","Epoch 68/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.2235 - accuracy: 0.9327 - val_loss: 0.4738 - val_accuracy: 0.8711\n","Epoch 69/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.2211 - accuracy: 0.9329 - val_loss: 0.4792 - val_accuracy: 0.8687\n","Epoch 70/170\n","118/118 [==============================] - 2s 16ms/step - loss: 0.2180 - accuracy: 0.9340 - val_loss: 0.4823 - val_accuracy: 0.8710\n","Epoch 71/170\n","118/118 [==============================] - 2s 16ms/step - loss: 0.2152 - accuracy: 0.9350 - val_loss: 0.4776 - val_accuracy: 0.8714\n","Epoch 72/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.2124 - accuracy: 0.9358 - val_loss: 0.4874 - val_accuracy: 0.8708\n","Epoch 73/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.2094 - accuracy: 0.9365 - val_loss: 0.4968 - val_accuracy: 0.8667\n","Epoch 74/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.2073 - accuracy: 0.9371 - val_loss: 0.4853 - val_accuracy: 0.8709\n","Epoch 75/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.2041 - accuracy: 0.9384 - val_loss: 0.4884 - val_accuracy: 0.8708\n","Epoch 76/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.2017 - accuracy: 0.9387 - val_loss: 0.4865 - val_accuracy: 0.8716\n","Epoch 77/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.1993 - accuracy: 0.9396 - val_loss: 0.4913 - val_accuracy: 0.8713\n","Epoch 78/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.1966 - accuracy: 0.9404 - val_loss: 0.4966 - val_accuracy: 0.8695\n","Epoch 79/170\n","118/118 [==============================] - 2s 19ms/step - loss: 0.1939 - accuracy: 0.9411 - val_loss: 0.4949 - val_accuracy: 0.8700\n","Epoch 80/170\n","118/118 [==============================] - 2s 16ms/step - loss: 0.1916 - accuracy: 0.9419 - val_loss: 0.4924 - val_accuracy: 0.8727\n","Epoch 81/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.1890 - accuracy: 0.9427 - val_loss: 0.5028 - val_accuracy: 0.8707\n","Epoch 82/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.1867 - accuracy: 0.9432 - val_loss: 0.4996 - val_accuracy: 0.8719\n","Epoch 83/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1843 - accuracy: 0.9442 - val_loss: 0.5010 - val_accuracy: 0.8712\n","Epoch 84/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.1819 - accuracy: 0.9446 - val_loss: 0.5053 - val_accuracy: 0.8705\n","Epoch 85/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1798 - accuracy: 0.9453 - val_loss: 0.5062 - val_accuracy: 0.8705\n","Epoch 86/170\n","118/118 [==============================] - 2s 16ms/step - loss: 0.1775 - accuracy: 0.9460 - val_loss: 0.5032 - val_accuracy: 0.8725\n","Epoch 87/170\n","118/118 [==============================] - 2s 16ms/step - loss: 0.1748 - accuracy: 0.9471 - val_loss: 0.5108 - val_accuracy: 0.8713\n","Epoch 88/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.1725 - accuracy: 0.9478 - val_loss: 0.5002 - val_accuracy: 0.8730\n","Epoch 89/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1706 - accuracy: 0.9482 - val_loss: 0.5065 - val_accuracy: 0.8727\n","Epoch 90/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1686 - accuracy: 0.9488 - val_loss: 0.5134 - val_accuracy: 0.8723\n","Epoch 91/170\n","118/118 [==============================] - 3s 21ms/step - loss: 0.1668 - accuracy: 0.9495 - val_loss: 0.5133 - val_accuracy: 0.8716\n","Epoch 92/170\n","118/118 [==============================] - 2s 19ms/step - loss: 0.1640 - accuracy: 0.9502 - val_loss: 0.5249 - val_accuracy: 0.8701\n","Epoch 93/170\n","118/118 [==============================] - 4s 32ms/step - loss: 0.1622 - accuracy: 0.9506 - val_loss: 0.5215 - val_accuracy: 0.8709\n","Epoch 94/170\n","118/118 [==============================] - 3s 28ms/step - loss: 0.1602 - accuracy: 0.9514 - val_loss: 0.5199 - val_accuracy: 0.8723\n","Epoch 95/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1585 - accuracy: 0.9515 - val_loss: 0.5343 - val_accuracy: 0.8703\n","Epoch 96/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1565 - accuracy: 0.9525 - val_loss: 0.5290 - val_accuracy: 0.8718\n","Epoch 97/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1543 - accuracy: 0.9532 - val_loss: 0.5242 - val_accuracy: 0.8731\n","Epoch 98/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1526 - accuracy: 0.9537 - val_loss: 0.5359 - val_accuracy: 0.8704\n","Epoch 99/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1507 - accuracy: 0.9541 - val_loss: 0.5437 - val_accuracy: 0.8690\n","Epoch 100/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.1490 - accuracy: 0.9545 - val_loss: 0.5434 - val_accuracy: 0.8699\n","Epoch 101/170\n","118/118 [==============================] - 2s 19ms/step - loss: 0.1472 - accuracy: 0.9551 - val_loss: 0.5347 - val_accuracy: 0.8726\n","Epoch 102/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.1453 - accuracy: 0.9558 - val_loss: 0.5416 - val_accuracy: 0.8709\n","Epoch 103/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1434 - accuracy: 0.9563 - val_loss: 0.5460 - val_accuracy: 0.8719\n","Epoch 104/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1420 - accuracy: 0.9566 - val_loss: 0.5521 - val_accuracy: 0.8709\n","Epoch 105/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1404 - accuracy: 0.9571 - val_loss: 0.5459 - val_accuracy: 0.8713\n","Epoch 106/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1385 - accuracy: 0.9577 - val_loss: 0.5478 - val_accuracy: 0.8729\n","Epoch 107/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1372 - accuracy: 0.9581 - val_loss: 0.5568 - val_accuracy: 0.8709\n","Epoch 108/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.1356 - accuracy: 0.9585 - val_loss: 0.5511 - val_accuracy: 0.8719\n","Epoch 109/170\n","118/118 [==============================] - 2s 17ms/step - loss: 0.1338 - accuracy: 0.9591 - val_loss: 0.5513 - val_accuracy: 0.8733\n","Epoch 110/170\n","118/118 [==============================] - 2s 16ms/step - loss: 0.1322 - accuracy: 0.9597 - val_loss: 0.5645 - val_accuracy: 0.8719\n","Epoch 111/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1309 - accuracy: 0.9600 - val_loss: 0.5627 - val_accuracy: 0.8716\n","Epoch 112/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1291 - accuracy: 0.9604 - val_loss: 0.5573 - val_accuracy: 0.8723\n","Epoch 113/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.1279 - accuracy: 0.9609 - val_loss: 0.5644 - val_accuracy: 0.8710\n","Epoch 114/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1260 - accuracy: 0.9613 - val_loss: 0.5707 - val_accuracy: 0.8720\n","Epoch 115/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1246 - accuracy: 0.9620 - val_loss: 0.5766 - val_accuracy: 0.8695\n","Epoch 116/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1230 - accuracy: 0.9625 - val_loss: 0.5765 - val_accuracy: 0.8700\n","Epoch 117/170\n","118/118 [==============================] - 2s 17ms/step - loss: 0.1214 - accuracy: 0.9628 - val_loss: 0.5719 - val_accuracy: 0.8722\n","Epoch 118/170\n","118/118 [==============================] - 2s 16ms/step - loss: 0.1207 - accuracy: 0.9629 - val_loss: 0.5750 - val_accuracy: 0.8724\n","Epoch 119/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1189 - accuracy: 0.9636 - val_loss: 0.5855 - val_accuracy: 0.8706\n","Epoch 120/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1179 - accuracy: 0.9638 - val_loss: 0.5816 - val_accuracy: 0.8720\n","Epoch 121/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1166 - accuracy: 0.9640 - val_loss: 0.5870 - val_accuracy: 0.8709\n","Epoch 122/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1150 - accuracy: 0.9646 - val_loss: 0.5975 - val_accuracy: 0.8710\n","Epoch 123/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.1137 - accuracy: 0.9651 - val_loss: 0.5957 - val_accuracy: 0.8706\n","Epoch 124/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1128 - accuracy: 0.9652 - val_loss: 0.5942 - val_accuracy: 0.8712\n","Epoch 125/170\n","118/118 [==============================] - 2s 15ms/step - loss: 0.1108 - accuracy: 0.9659 - val_loss: 0.5927 - val_accuracy: 0.8711\n","Epoch 126/170\n","118/118 [==============================] - 2s 17ms/step - loss: 0.1101 - accuracy: 0.9659 - val_loss: 0.5963 - val_accuracy: 0.8699\n","Epoch 127/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.1086 - accuracy: 0.9662 - val_loss: 0.5997 - val_accuracy: 0.8705\n","Epoch 128/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1075 - accuracy: 0.9666 - val_loss: 0.6050 - val_accuracy: 0.8702\n","Epoch 129/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1064 - accuracy: 0.9671 - val_loss: 0.6113 - val_accuracy: 0.8684\n","Epoch 130/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.1048 - accuracy: 0.9675 - val_loss: 0.6069 - val_accuracy: 0.8703\n","Epoch 131/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1044 - accuracy: 0.9675 - val_loss: 0.6166 - val_accuracy: 0.8704\n","Epoch 132/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.1032 - accuracy: 0.9680 - val_loss: 0.6119 - val_accuracy: 0.8707\n","Epoch 133/170\n","118/118 [==============================] - 2s 17ms/step - loss: 0.1018 - accuracy: 0.9682 - val_loss: 0.6120 - val_accuracy: 0.8714\n","Epoch 134/170\n","118/118 [==============================] - 2s 20ms/step - loss: 0.1005 - accuracy: 0.9687 - val_loss: 0.6199 - val_accuracy: 0.8706\n","Epoch 135/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.0998 - accuracy: 0.9687 - val_loss: 0.6266 - val_accuracy: 0.8695\n","Epoch 136/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.0983 - accuracy: 0.9693 - val_loss: 0.6228 - val_accuracy: 0.8713\n","Epoch 137/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.0970 - accuracy: 0.9699 - val_loss: 0.6238 - val_accuracy: 0.8706\n","Epoch 138/170\n","118/118 [==============================] - 2s 15ms/step - loss: 0.0965 - accuracy: 0.9698 - val_loss: 0.6339 - val_accuracy: 0.8701\n","Epoch 139/170\n","118/118 [==============================] - 2s 15ms/step - loss: 0.0951 - accuracy: 0.9703 - val_loss: 0.6366 - val_accuracy: 0.8699\n","Epoch 140/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.0946 - accuracy: 0.9703 - val_loss: 0.6341 - val_accuracy: 0.8700\n","Epoch 141/170\n","118/118 [==============================] - 2s 17ms/step - loss: 0.0937 - accuracy: 0.9708 - val_loss: 0.6401 - val_accuracy: 0.8708\n","Epoch 142/170\n","118/118 [==============================] - 2s 16ms/step - loss: 0.0920 - accuracy: 0.9713 - val_loss: 0.6410 - val_accuracy: 0.8696\n","Epoch 143/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.0912 - accuracy: 0.9717 - val_loss: 0.6374 - val_accuracy: 0.8721\n","Epoch 144/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.0905 - accuracy: 0.9716 - val_loss: 0.6377 - val_accuracy: 0.8707\n","Epoch 145/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.0891 - accuracy: 0.9719 - val_loss: 0.6546 - val_accuracy: 0.8692\n","Epoch 146/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.0888 - accuracy: 0.9720 - val_loss: 0.6495 - val_accuracy: 0.8704\n","Epoch 147/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.0874 - accuracy: 0.9724 - val_loss: 0.6517 - val_accuracy: 0.8702\n","Epoch 148/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.0863 - accuracy: 0.9730 - val_loss: 0.6623 - val_accuracy: 0.8682\n","Epoch 149/170\n","118/118 [==============================] - 2s 16ms/step - loss: 0.0859 - accuracy: 0.9728 - val_loss: 0.6590 - val_accuracy: 0.8695\n","Epoch 150/170\n","118/118 [==============================] - 2s 16ms/step - loss: 0.0845 - accuracy: 0.9734 - val_loss: 0.6590 - val_accuracy: 0.8702\n","Epoch 151/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.0837 - accuracy: 0.9737 - val_loss: 0.6538 - val_accuracy: 0.8708\n","Epoch 152/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.0833 - accuracy: 0.9737 - val_loss: 0.6599 - val_accuracy: 0.8705\n","Epoch 153/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.0823 - accuracy: 0.9739 - val_loss: 0.6707 - val_accuracy: 0.8690\n","Epoch 154/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.0815 - accuracy: 0.9743 - val_loss: 0.6724 - val_accuracy: 0.8693\n","Epoch 155/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.0801 - accuracy: 0.9748 - val_loss: 0.6746 - val_accuracy: 0.8694\n","Epoch 156/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.0800 - accuracy: 0.9747 - val_loss: 0.6708 - val_accuracy: 0.8701\n","Epoch 157/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.0789 - accuracy: 0.9748 - val_loss: 0.6839 - val_accuracy: 0.8679\n","Epoch 158/170\n","118/118 [==============================] - 2s 16ms/step - loss: 0.0780 - accuracy: 0.9750 - val_loss: 0.6764 - val_accuracy: 0.8693\n","Epoch 159/170\n","118/118 [==============================] - 2s 15ms/step - loss: 0.0772 - accuracy: 0.9754 - val_loss: 0.6799 - val_accuracy: 0.8689\n","Epoch 160/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.0763 - accuracy: 0.9756 - val_loss: 0.6855 - val_accuracy: 0.8691\n","Epoch 161/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.0757 - accuracy: 0.9759 - val_loss: 0.7003 - val_accuracy: 0.8663\n","Epoch 162/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.0750 - accuracy: 0.9759 - val_loss: 0.6894 - val_accuracy: 0.8693\n","Epoch 163/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.0742 - accuracy: 0.9765 - val_loss: 0.6938 - val_accuracy: 0.8686\n","Epoch 164/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.0738 - accuracy: 0.9765 - val_loss: 0.6970 - val_accuracy: 0.8693\n","Epoch 165/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.0725 - accuracy: 0.9768 - val_loss: 0.6902 - val_accuracy: 0.8699\n","Epoch 166/170\n","118/118 [==============================] - 2s 19ms/step - loss: 0.0720 - accuracy: 0.9766 - val_loss: 0.6945 - val_accuracy: 0.8698\n","Epoch 167/170\n","118/118 [==============================] - 2s 16ms/step - loss: 0.0711 - accuracy: 0.9771 - val_loss: 0.7064 - val_accuracy: 0.8684\n","Epoch 168/170\n","118/118 [==============================] - 2s 13ms/step - loss: 0.0707 - accuracy: 0.9772 - val_loss: 0.6983 - val_accuracy: 0.8698\n","Epoch 169/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.0705 - accuracy: 0.9771 - val_loss: 0.7041 - val_accuracy: 0.8691\n","Epoch 170/170\n","118/118 [==============================] - 2s 14ms/step - loss: 0.0689 - accuracy: 0.9776 - val_loss: 0.7078 - val_accuracy: 0.8681\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f661810e850>"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# COMPILING THE MODEL (encoder_input_data + decoder_input_data -- > decoder_output_data)\n","\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","model.compile(optimizer = 'rmsprop',\n","              loss = 'categorical_crossentropy',\n","              metrics = ['accuracy'])\n","\n","\n","# RUN THE MODEL:\n","model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n","          batch_size = batch_size,\n","          epochs = 170,\n","          validation_split = 0.25)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1678794732911,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"LytmFVo1mIhM"},"outputs":[],"source":["# Sampling Inferencing :\n","# Steps :\n","# 1) encode input and retrive initital decoder state\n","# 2) run one step of decoder with the initial state and 'start of sequence' token as target\n","# 3) output will be the next target token\n","# 4) Repeat with current target token and current states ."]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1678794732912,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"UL9lXTHh2eI0"},"outputs":[],"source":["# DEFINING THE SAMPLING MODEL:\n","\n","encoder_model = Model(encoder_inputs, encoder_states)\n","\n","decoder_state_input_h = Input(shape = (latent_dim, ))\n","decoder_state_input_c = Input(shape = (latent_dim, ))\n","decoder_state_inputs = [decoder_state_input_h,decoder_state_input_c ]\n","\n","decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state= decoder_state_inputs)\n","\n","decoder_states  =  [state_h, state_c] \n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","decoder_model = Model([decoder_inputs]+ decoder_state_inputs, [decoder_outputs] + decoder_states)"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1678794732912,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"gKQbuG0k4wUH"},"outputs":[],"source":["# Reverse look up token index to decode sequence back to something readable:\n","reverse_input_char_index = dict((i,char) for char, i in input_token_index.items())\n","\n","reverse_target_char_index  = dict((i, char) for char, i in target_token_index.items())\n"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":630,"status":"ok","timestamp":1678795094974,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"H1BuRYXM39dU"},"outputs":[],"source":["def decode_sequence(input_seq):\n","    # Encode the input as state vectors.\n","    states_value = encoder_model.predict(input_seq, verbose = 0)\n","\n","    # Generate empty target sequence of length 1.\n","    target_seq = np.zeros((1, 1, num_decoder_tokens))\n","    # Populate the first character of target sequence with the start character.\n","    target_seq[0, 0, target_token_index['\\t']] = 1.\n","\n","    # Sampling loop for a batch of sequences\n","    # (to simplify, here we assume a batch of size 1).\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict(\n","            [target_seq] + states_value, verbose = 0)\n","\n","        # Sample a token\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_char = reverse_target_char_index[sampled_token_index]\n","        decoded_sentence += sampled_char\n","\n","        # Exit condition: either hit max length\n","        # or find stop character.\n","        if (sampled_char == '\\n' or\n","           len(decoded_sentence) > max_decoder_seq_len):\n","            stop_condition = True\n","\n","        # Update the target sequence (of length 1).\n","        target_seq = np.zeros((1, 1, num_decoder_tokens))\n","        target_seq[0, 0, sampled_token_index] = 1.\n","\n","        # Update states\n","        states_value = [h, c]\n","\n","    return decoded_sentence"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56627,"status":"ok","timestamp":1678795177569,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"9G5sLcFR5lOE","outputId":"7260d91e-a142-41b0-f09a-7a7710567861"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","  Input Sequence    : Help!\n","  Decoded Sequence  : Aide-moi !\n","\n","  \n","\n","  Input Sequence    : Hide.\n","  Decoded Sequence  : Cachez-vous.\n","\n","  \n","\n","  Input Sequence    : Hide.\n","  Decoded Sequence  : Cachez-vous.\n","\n","  \n","\n","  Input Sequence    : Jump!\n","  Decoded Sequence  : Saute.\n","\n","  \n","\n","  Input Sequence    : Jump.\n","  Decoded Sequence  : Saute.\n","\n","  \n","\n","  Input Sequence    : Stop!\n","  Decoded Sequence  : Arrête-toi !\n","\n","  \n","\n","  Input Sequence    : Stop!\n","  Decoded Sequence  : Arrête-toi !\n","\n","  \n","\n","  Input Sequence    : Stop!\n","  Decoded Sequence  : Arrête-toi !\n","\n","  \n","\n","  Input Sequence    : Wait!\n","  Decoded Sequence  : Attendez.\n","\n","  \n","\n","  Input Sequence    : Wait!\n","  Decoded Sequence  : Attendez.\n","\n","  \n","\n","  Input Sequence    : Wait!\n","  Decoded Sequence  : Attendez.\n","\n","  \n","\n","  Input Sequence    : Wait.\n","  Decoded Sequence  : Attends.\n","\n","  \n","\n","  Input Sequence    : Wait.\n","  Decoded Sequence  : Attends.\n","\n","  \n","\n","  Input Sequence    : Wait.\n","  Decoded Sequence  : Attends.\n","\n","  \n","\n","  Input Sequence    : Wait.\n","  Decoded Sequence  : Attends.\n","\n","  \n","\n","  Input Sequence    : Begin.\n","  Decoded Sequence  : Commence.\n","\n","  \n","\n","  Input Sequence    : Begin.\n","  Decoded Sequence  : Commence.\n","\n","  \n","\n","  Input Sequence    : Go on.\n","  Decoded Sequence  : Va-tu.\n","\n","  \n","\n","  Input Sequence    : Go on.\n","  Decoded Sequence  : Va-tu.\n","\n","  \n","\n","  Input Sequence    : Go on.\n","  Decoded Sequence  : Va-tu.\n","\n","  \n","\n","  Input Sequence    : Hello!\n","  Decoded Sequence  : Bonjour.\n","\n","  \n","\n","  Input Sequence    : Hello!\n","  Decoded Sequence  : Bonjour.\n","\n","  \n","\n","  Input Sequence    : Hello.\n","  Decoded Sequence  : Bonjour.\n","\n","  \n","\n","  Input Sequence    : Hello.\n","  Decoded Sequence  : Bonjour.\n","\n","  \n","\n","  Input Sequence    : Hello.\n","  Decoded Sequence  : Bonjour.\n","\n","  \n","\n","  Input Sequence    : Hello.\n","  Decoded Sequence  : Bonjour.\n","\n","  \n","\n","  Input Sequence    : I see.\n","  Decoded Sequence  : Je comprends.\n","\n","  \n","\n","  Input Sequence    : I see.\n","  Decoded Sequence  : Je comprends.\n","\n","  \n","\n","  Input Sequence    : I try.\n","  Decoded Sequence  : J'essaye.\n","\n","  \n","\n","  Input Sequence    : I won!\n","  Decoded Sequence  : J'ai gagné.\n","\n","  \n","\n","  Input Sequence    : I won!\n","  Decoded Sequence  : J'ai gagné.\n","\n","  \n","\n","  Input Sequence    : I won.\n","  Decoded Sequence  : J'ai gagné.\n","\n","  \n","\n","  Input Sequence    : Oh no!\n","  Decoded Sequence  : Pous l'abouisur !\n","\n","  \n","\n","  Input Sequence    : Relax.\n","  Decoded Sequence  : Détends-toi.\n","\n","  \n","\n","  Input Sequence    : Relax.\n","  Decoded Sequence  : Détends-toi.\n","\n","  \n","\n","  Input Sequence    : Relax.\n","  Decoded Sequence  : Détends-toi.\n","\n","  \n","\n","  Input Sequence    : Relax.\n","  Decoded Sequence  : Détends-toi.\n","\n","  \n","\n","  Input Sequence    : Relax.\n","  Decoded Sequence  : Détends-toi.\n","\n","  \n","\n","  Input Sequence    : Relax.\n","  Decoded Sequence  : Détends-toi.\n","\n","  \n","\n","  Input Sequence    : Relax.\n","  Decoded Sequence  : Détends-toi.\n","\n","  \n","\n","  Input Sequence    : Relax.\n","  Decoded Sequence  : Détends-toi.\n","\n","  \n","\n","  Input Sequence    : Relax.\n","  Decoded Sequence  : Détends-toi.\n","\n","  \n","\n","  Input Sequence    : Relax.\n","  Decoded Sequence  : Détends-toi.\n","\n","  \n","\n","  Input Sequence    : Relax.\n","  Decoded Sequence  : Détends-toi.\n","\n","  \n","\n","  Input Sequence    : Relax.\n","  Decoded Sequence  : Détends-toi.\n","\n","  \n","\n","  Input Sequence    : Smile.\n","  Decoded Sequence  : Souris pour la caméra.\n","\n","  \n","\n","  Input Sequence    : Smile.\n","  Decoded Sequence  : Souris pour la caméra.\n","\n","  \n","\n","  Input Sequence    : Smile.\n","  Decoded Sequence  : Souris pour la caméra.\n","\n","  \n","\n","  Input Sequence    : Sorry?\n","  Decoded Sequence  : Pardon ?\n","\n","  \n","\n","  Input Sequence    : Attack!\n","  Decoded Sequence  : Attaquez !\n","\n","  \n","\n","  Input Sequence    : Attack!\n","  Decoded Sequence  : Attaquez !\n","\n","  \n","\n","  Input Sequence    : Attack!\n","  Decoded Sequence  : Attaquez !\n","\n","  \n","\n","  Input Sequence    : Attack!\n","  Decoded Sequence  : Attaquez !\n","\n","  \n","\n","  Input Sequence    : Buy it.\n","  Decoded Sequence  : Achète-la !\n","\n","  \n","\n","  Input Sequence    : Buy it.\n","  Decoded Sequence  : Achète-la !\n","\n","  \n","\n","  Input Sequence    : Buy it.\n","  Decoded Sequence  : Achète-la !\n","\n","  \n","\n","  Input Sequence    : Buy it.\n","  Decoded Sequence  : Achète-la !\n","\n","  \n","\n","  Input Sequence    : Cheers!\n","  Decoded Sequence  : Santé !\n","\n","  \n","\n","  Input Sequence    : Cheers!\n","  Decoded Sequence  : Santé !\n","\n","  \n","\n","  Input Sequence    : Cheers!\n","  Decoded Sequence  : Santé !\n","\n","  \n","\n","  Input Sequence    : Cheers!\n","  Decoded Sequence  : Santé !\n","\n","  \n","\n","  Input Sequence    : Eat it.\n","  Decoded Sequence  : Mangez-le.\n","\n","  \n","\n","  Input Sequence    : Eat it.\n","  Decoded Sequence  : Mangez-le.\n","\n","  \n","\n","  Input Sequence    : Get up.\n","  Decoded Sequence  : Décampez !\n","\n","  \n","\n","  Input Sequence    : Get up.\n","  Decoded Sequence  : Décampez !\n","\n","  \n","\n","  Input Sequence    : Get up.\n","  Decoded Sequence  : Décampez !\n","\n","  \n","\n","  Input Sequence    : Go now.\n","  Decoded Sequence  : Vas-y maintenant.\n","\n","  \n","\n","  Input Sequence    : Go now.\n","  Decoded Sequence  : Vas-y maintenant.\n","\n","  \n","\n","  Input Sequence    : Go now.\n","  Decoded Sequence  : Vas-y maintenant.\n","\n","  \n","\n","  Input Sequence    : Got it!\n","  Decoded Sequence  : Dégage !\n","\n","  \n"]}],"source":["# Initiating the for loop :\n","\n","for seq_index in range(30,100):\n","  # Taking one sequence from training set to decode:\n","  input_seq = encoder_input_data[seq_index: seq_index+1]\n","  decode_sent = decode_sequence(input_seq)\n","\n","  print (f'''\n","  Input Sequence    : {input_text[seq_index]}\n","  Decoded Sequence  : {decode_sent}\n","  ''')"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1678794741652,"user":{"displayName":"SARVESH YADAV","userId":"08025523922383380882"},"user_tz":-330},"id":"C-46vFDp6af4"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
